---
title: "Ketten-Questionnaire"
author: "Christian 'Becko' Beck"
date: "21 Oktober 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Import

Data had to be imported. The original xlsx was improved: two items (Person2 - Pompfe; 103 - best number of stones) were seperated into item groups, since multiple selections were effectively possible and encuraged by the questions. The file was exported into a csv for import into R (note: i know of the package 'xlsx', but it often does not what i want to do, while the other way through a csv has been profen to be rock solid)

```{r import}
Testergebnis.Fragebogen <- read.csv2("~/ownCloud/Programming/jugger_data/chain2016/Testergebnis Fragebogen.csv", row.names=1, quote="'", stringsAsFactors=FALSE)

summary(Testergebnis.Fragebogen)
```

## Cleaning

```{r clean, results='hide', warning=FALSE,collapse=TRUE}
library(magrittr)
library(dplyr)

Testergebnis.Fragebogen %<>% select(-Person.2, -X103)
Testergebnis.Fragebogen$P2.Stab[is.na(Testergebnis.Fragebogen$P2.Stab)] <- 0
Testergebnis.Fragebogen$P2.LP[is.na(Testergebnis.Fragebogen$P2.LP)] <- 0
Testergebnis.Fragebogen$P2.Schild[is.na(Testergebnis.Fragebogen$P2.Schild)] <- 0
Testergebnis.Fragebogen$P2.Q[is.na(Testergebnis.Fragebogen$P2.Q)] <- 0
Testergebnis.Fragebogen$P2.Kette[is.na(Testergebnis.Fragebogen$P2.Kette)] <- 0
Testergebnis.Fragebogen$P2.Quick[is.na(Testergebnis.Fragebogen$P2.Quick)] <- 0

Testergebnis.Fragebogen$X103.5[is.na(Testergebnis.Fragebogen$X103.5)] <- 0
Testergebnis.Fragebogen$X103.6[is.na(Testergebnis.Fragebogen$X103.6)] <- 0
Testergebnis.Fragebogen$X103.7[is.na(Testergebnis.Fragebogen$X103.7)] <- 0
Testergebnis.Fragebogen$X103.8[is.na(Testergebnis.Fragebogen$X103.8)] <- 0

Testergebnis.Fragebogen %<>% mutate(P2.Stab = as.factor(P2.Stab), P2.LP = as.factor(P2.LP), P2.Schild = as.factor(P2.Schild), P2.Q = as.factor(P2.Q), P2.Quick = as.factor(P2.Quick), P2.Kette = as.factor(P2.Kette))

```

Note: There are a lot of questions that are asked wrong - the meaning of some of the answers is in many cases not clear. This is due to relative statements with no given baseline in the questions. Given the context and that the hypothesis to each statement is known (or guessable) beforehand makes it still possible - but quit dirty - to analyse all questions. However i issue a warning to not give these results to much credibility.

## Basic Visualisation and exploration

Note: Question Person.2 (which is your MAIN Pompfe) is somewhat ill posed. However important in the current context is just the number of chain players, all others can be treated the same.

* Count of questionnaires: `r nrow(Testergebnis.Fragebogen)`
* Count of chains: `r sum(Testergebnis.Fragebogen$P2.Kette == 1)`
* Ratio of chains: `r mean(Testergebnis.Fragebogen$P2.Kette == 1)`

```{r vis1, results='hide', warning=FALSE, message=FALSE}
library(ggplot2)
library(reshape2)
library(knitr)

# boxplot for each score
ggplot(melt(Testergebnis.Fragebogen %>% select(-Person.1, -P2.Q,-P2.Stab,-P2.LP,-P2.Schild,-P2.Quick, -P2.Kette, -X103.5,-X103.6,-X103.7,-X103.8, -X93, -X51,-X52))) +
  geom_boxplot(aes(x = variable, y = value)) +
  theme_classic() + theme(axis.text.x = element_text(angle = 90)) +
  scale_y_continuous(name = "Antworten", breaks = 1:5, minor_breaks = NULL, labels = c("Trifft nicht zu","Trifft eher nicht zu","unentscheiden","Trifft eher zu", "Trifft voll zu")) +
  scale_x_discrete(name = "Fragen")

# Aggregate of all scores
Testergebnis.stats <- Testergebnis.Fragebogen %>% select(-Person.1, -P2.Q,-P2.Stab,-P2.LP,-P2.Schild,-P2.Quick, -P2.Kette, -X103.5,-X103.6,-X103.7,-X103.8, -X93, -X51,-X52) %>% melt() %>% group_by(variable) %>% summarise(avg = mean(value, na.rm = TRUE), var = var(value, na.rm = TRUE))
ggplot(Testergebnis.stats) +
  geom_bar(aes(x = variable, y = avg),stat = "identity") +
  geom_errorbar(aes(x = variable, ymin = avg, ymax = avg+var)) +
  coord_cartesian(ylim = c(1,6)) +
  theme_classic() + theme(axis.text.x = element_text(angle = 90)) +
  scale_y_continuous(name = "Antworten", breaks = 1:5, minor_breaks = NULL, labels = c("Trifft nicht zu","Trifft eher nicht zu","unentscheiden","Trifft eher zu", "Trifft voll zu")) +
  scale_x_discrete(name = "Fragen")

# Aggregate of all scores nach Kette/nicht-Kette
Testergebnis.stats2 <- Testergebnis.Fragebogen %>% select(-Person.1, -P2.Q,-P2.Stab,-P2.LP,-P2.Schild,-P2.Quick, -X103.5,-X103.6,-X103.7,-X103.8, -X93, -X51,-X52) %>% melt(id.vars = "P2.Kette") %>% group_by(P2.Kette, variable) %>% summarise(avg = mean(value, na.rm = TRUE), var = var(value, na.rm = TRUE))
ggplot(Testergebnis.stats2) +
  geom_bar(aes(x = variable, y = avg, fill = P2.Kette),stat = "identity", position = "dodge") +
  geom_errorbar(aes(x = variable, ymin = avg, ymax = avg+var, fill = P2.Kette), position = "dodge", width = 0.9) +
  coord_cartesian(ylim = c(1,6)) +
  theme_classic() + theme(axis.text.x = element_text(angle = 90)) +
  scale_y_continuous(name = "Antworten", breaks = 1:5, minor_breaks = NULL, labels = c("Trifft nicht zu","Trifft eher nicht zu","unentscheiden","Trifft eher zu", "Trifft voll zu")) +
  scale_x_discrete(name = "Fragen") +
#  scale_fill_discrete(name = "Kette") +
  scale_fill_grey(name = "Kette?")

```

## First statistics

```{r stats1, collapse=TRUE, warning=FALSE, message=FALSE}

chain.stats <- Testergebnis.Fragebogen %>% select(-Person.1, -P2.Q,-P2.Stab,-P2.LP,-P2.Schild,-P2.Quick, -P2.Kette, -X103.5,-X103.6,-X103.7,-X103.8, -X93, -X51,-X52)

##### normality
ntest <- data.frame(Question = colnames(chain.stats), W = NA, p = NA, "H0 rejected?" = NA, stringsAsFactors = FALSE)
for (ci in 1:ncol(chain.stats)) {
  st <- shapiro.test(x = chain.stats[,ci])
  ntest[ci,2] <- st$statistic
  ntest[ci,3] <- st$p.value
  ntest[ci,4] <- st$p.value < 0.05
}

kable(x = ntest, digits = 2,
      caption = "Results of the Shapiro-test for normality. TRUE means H0 was rejected at confidence level 0.05.")

###### H0 test
wtest <- data.frame(Question = colnames(chain.stats), V = NA, p = NA, "H0 rejected?" = NA, "H0 rejected? Boferroni" = NA, stringsAsFactors = FALSE)
for (ci in 1:ncol(chain.stats)) {
  wt <- wilcox.test(x = chain.stats[,ci], alternative = "two.sided", mu = 3)
  wtest[ci,2] <- wt$statistic
  wtest[ci,3] <- wt$p.value
  wtest[ci,4] <- wt$p.value < 0.05
  wtest[ci,5] <- wt$p.value < 0.05 / ncol(chain.stats)
}

kable(x = wtest, digits = 2,
      caption = "Results of the Wilcoxon signed rank test with continuity correction. TRUE means H0 was rejected at confidence level 0.05 - either without or with Bonferroni correction for multiple comparison.")
```

Note: the above test confirm Gerds intuition on most of the questions and answers.

Another note: I hoped for the data to be such that i can highlight some possible p-Hacking in there to support another argument about statistics - how one can (intended or not) shift the results of an anlysis based on his or her prejudices. But "sadly" the data did not follow and so even with two-sided testing and quit conservative Bonferroni correction the pattern of significant answers emerges. (ps: I'm not t-testing here, because the data is not normal enough)

Next: group differences between chain and non-chain players!
```{r stats2, collapse=TRUE, warning=FALSE, message=FALSE}

chain.stats <- Testergebnis.Fragebogen %>% select(-Person.1, -P2.Q,-P2.Stab,-P2.LP,-P2.Schild,-P2.Quick, -X103.5,-X103.6,-X103.7,-X103.8, -X93, -X51,-X52)

###### two-sample H0 test
twtest <- data.frame(Question = colnames(chain.stats)[-1], V = NA, p = NA, "H0 rejected?" = NA, "H0 rejected? Boferroni" = NA, stringsAsFactors = FALSE)
for (ci in 2:ncol(chain.stats)) {
  twt <- wilcox.test(x = chain.stats[chain.stats[,1] == 1,ci], y = chain.stats[chain.stats[,1] != 1,ci], alternative = "two.sided")
  twtest[ci-1,2] <- twt$statistic
  twtest[ci-1,3] <- twt$p.value
  twtest[ci-1,4] <- twt$p.value < 0.05
  twtest[ci-1,5] <- twt$p.value < 0.05 / ncol(chain.stats)
}

kable(x = twtest, digits = 2,
      caption = "Results of the two-sample Wilcoxon signed rank test with continuity correction - differences in ratings between chain players and non-chain players. TRUE means H0 was rejected at confidence level 0.05 - either without or with Bonferroni correction for multiple comparison.")

## 103 test?

```

Now it's getting interesting (i report only Bonferroni corrected significance, since no hypothesis exists):

* On doubles chain players and non-chain players seem to disagree (Q55)
* The three questions about the value of chain specialities - such as hit-rate, reach and pin (Q91, Q92, Q95) - are seen differently by chains than by non-chains.

## Relations

Years of experience against ratings and ratings against ratings:

```{r years}

chain.stats <- Testergebnis.Fragebogen %>% select(-P2.Q,-P2.Stab,-P2.LP,-P2.Schild,-P2.Quick,-P2.Kette, -X103.5,-X103.6,-X103.7,-X103.8, -X51,-X52)

chain.stats.cor <- chain.stats %>% psych::corr.test(use = "pairwise", method = "pearson", adjust = "holm")
# note: holm multiple comparison correction is already applied here

kable(x = data.frame(Question = colnames(chain.stats.cor$r)[-1],
                     ChainR = chain.stats.cor$r[-1,"Person.1"],
                     ChainP = chain.stats.cor$p[-1,"Person.1"],
                     ChainPs = chain.stats.cor$p[-1,"Person.1"] < 0.05),
      digits = 2, caption = "Correlation results of years of experience (Person.1) with all other ratings")

```

Note on years: interesting relations of experience 

* more experience, less important was the missing of tactical interactions with chains (Q30)
* more experience, less was the game perceived influence of the rule change (Q43)
* more experience, less faster/wilder/stressful (Q98)

```{r corrs.vis1}
library(reshape2)
library(ggplot2)

chain.stats.cor$r[upper.tri(chain.stats.cor$r, diag = TRUE)] <- NA
chain.stats.cor <- chain.stats.cor %$% inner_join(melt(r), melt(p), by = c("Var1" = "Var1", "Var2" = "Var2")) %>% rename(r = value.x, p = value.y) %>% filter(!is.na(r))

ggplot(chain.stats.cor, aes(Var1, Var2, fill = r)) + geom_tile(colour = "white") + 
  geom_text(aes(Var1, Var2, label = ifelse(p < 0.05, "*", "")), color = "red", size = 4) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1), axis.title.x = element_blank(),
        axis.title.y = element_blank(), panel.grid.major = element_blank(), panel.border = element_blank(), panel.background = element_blank(), axis.ticks = element_blank()) +
  scale_fill_gradient(low = "black", high = "white", name = "Pearson\nCorrelation")
# red dots mark significant correlations
```

It is a bit confusing - many variables (34 variables resulting in 561 unique correlations) and many significant correlations (147!). Lets try something else more visually convenient: Let's treat the correlation matrix as a adjacency matrix (thresholded by p < 0.05)

Also note: The high number of significant correlations is a hint that the items are not meassuring independent components, but rather rely on a few latent dimensions. Lets test this first!

```{r prcomp}
chain.stats <- Testergebnis.Fragebogen %>% select(-Person.1, -P2.Q,-P2.Stab,-P2.LP,-P2.Schild,-P2.Quick,-P2.Kette, -X103.5,-X103.6,-X103.7,-X103.8, -X51,-X52)

factors <- prcomp(formula = ~ ., data = chain.stats, center = TRUE, scale = TRUE, retx = TRUE, na.action = na.omit)

kable(x = data.frame(PC = colnames(factors$rotation), Standard.deviations = round(factors$sdev,2)), digits = 2,
      caption = "Standard deviations of all primary components of the questionnaire data set.")

#kable(x = as.data.frame(factors$rotation), digits = 2,
#      caption = "Rotations matrix of the primary factor analysis. Shows decomposition of the factors into the set of asked questions.")
```

Only eight components are within this one data set and the last one is effectively zero, which reduces the number of componentes to 7. At first this seems like an interesting result, but hold on! How many rows of the result table are without any missing values? Exactly 8! Well that explains a lot ... But lets have a look at the questions without answers: It turns out that question 20 askes only chain players (and thus 34 missing values), 30 asks only Pompfers (8 mising values - discrepancies with the number sof the question Person2 are due to the fact that Person2 asks only for the main Pompfe, while Q20 and Q30 apply also for secondary and tertiary Pompfe), 53 and 54 are only applicable if a chain-double occured to that player (14 and 11 missing values). This is good news, since subjects read and followed the instructions :) So next take on primary components:

```{r prcomp2}
library(ggplot2)
ggplot(data = data.frame(Question = colnames(chain.stats), N.missing.values = colSums(is.na(chain.stats))), aes(x = Question, y = N.missing.values)) + geom_bar(stat = "identity")

chain.stats <- Testergebnis.Fragebogen %>% select(-Person.1, -P2.Q,-P2.Stab,-P2.LP,-P2.Schild,-P2.Quick,-P2.Kette, -X103.5,-X103.6,-X103.7,-X103.8, -X51,-X52, -X20, -X30, -X53, -X54)

factors <- prcomp(formula = ~ ., data = chain.stats, center = TRUE, scale = TRUE, retx = TRUE, na.action = na.omit)

kable(x = data.frame(PC = colnames(factors$rotation), Standard.deviations = round(factors$sdev,2)), digits = 2,
      caption = "Standard deviations of all primary components of the questionnaire data set.")

ggplot(data = data.frame(pos = 1:length(colnames(factors$rotation)),PC = colnames(factors$rotation), fraction = 1 - cumsum(factors$sdev)/sum(factors$sdev)), aes(x = pos, y = fraction)) + geom_area() #+ geom_bar(stat = "identity")

kable(x = as.data.frame(factors$rotation), digits = 2,
      caption = "Rotations matrix of the primary factor analysis. Shows decomposition of the factors into the set of asked questions.")

```

The resulting 29 questions produce a typical decrease in primary component power. It shows that i can drop 15 factors (of 29) and still only loos less than 20% of the variance within the data. This serves as a minor hint that there might be some hidden structure in the data, although it is weak since the steepness of the decrease is not that radical. But as a remninder keep in mind the highest values of the first component: Q55, Q95, Q92, Q56, Q91, Q96, Q102, Q63, Q61, Q97, ...

So much for that. Now back to the graph analysis. As a reminder: I wanted to highlight some structures of the correelation matrix.

```{r corrs.vis2}
library(visNetwork)

chain.stats.cor.nw <- chain.stats.cor %>% filter(Var1 != "Person.1", Var2 != "Person.1", p < 0.05)

cv <- chain.stats.cor.nw %$% visNetwork(nodes = data.frame(id = unique(chain.stats.cor$Var1),
                                                           label = unique(chain.stats.cor$Var1),
                                                           title = paste("<b>Question", unique(chain.stats.cor$Var1), "</b></br>",
                                                                         "Fill in question texts later")),
                 edges = data.frame(to = Var1, from = Var2,
                                    title = paste("<b>",Var1,"~",Var2,"</b></br>", "r =",  r),
                                    value = abs(r))) %>%
  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE)

cv
```

Still a lot to digest within one picture - a dense strongly interconnected graph. But look: It's interactive!!! This neat feature allows you to explore the structure by hand. Just hover, click, drag and drop.

However i still have the feeling that this visualisation doesn't tell me everything - still it gives me a very good intuition of whats going on. So lets drill in with some graph methods.

```{r corrs.cliques, warning=FALSE, message=FALSE}
library(igraph) # just for the convenient implementation of largest.clique
cvig <- chain.stats.cor.nw %$% graph.data.frame(data.frame(to = Var1, from = Var2), directed = FALSE)
largest.cliques(cvig)
```



